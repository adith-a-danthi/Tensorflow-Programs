{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynR3Dhj6DM5h",
        "colab_type": "text"
      },
      "source": [
        "Below is code with a link to a happy or sad dataset which contains 80 images, 40 happy and 40 sad. It is to download the data onto the machine's storage.\n",
        "To replicate the same on a local machine use the link to download the dataset and seperate it into the respective folders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiTtO3-yCn3F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "74933adb-2fd1-4ec7-b61d-42e53d98f9da"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip \\\n",
        "    -O /tmp/happy-or-sad.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-26 14:44:32--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.212.128, 172.217.214.128, 2607:f8b0:4001:c14::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.212.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2670333 (2.5M) [application/zip]\n",
            "Saving to: ‘/tmp/happy-or-sad.zip’\n",
            "\n",
            "\r/tmp/happy-or-sad.z   0%[                    ]       0  --.-KB/s               \r/tmp/happy-or-sad.z 100%[===================>]   2.55M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-06-26 14:44:32 (108 MB/s) - ‘/tmp/happy-or-sad.zip’ saved [2670333/2670333]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bB80Lo2rDktr",
        "colab_type": "text"
      },
      "source": [
        "The following python code will use the OS library to use Operating System libraries, giving you access to the file system, and the zipfile library allowing you to unzip the data.\n",
        "To replicate on local system mention the local path to the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Na97Y85EEZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/tmp/happy-or-sad.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp/h-or-s\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz_Sz4x7ElJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_happy_sad_model():\n",
        "\n",
        "    DESIRED_ACCURACY = 0.999\n",
        "\n",
        "    class myCallback(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_end(self, epoch, logs={}):\n",
        "            if (logs.get('acc') > DESIRED_ACCURACY):\n",
        "                print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "                self.model.stop_training = True\n",
        "\n",
        "    callbacks = myCallback()\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150,150,3)),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')      \n",
        "    ])\n",
        "\n",
        "    from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                 optimizer=RMSprop(lr=0.001),\n",
        "                 metrics=['acc'])\n",
        "        \n",
        "\n",
        "    # This code block should create an instance of an ImageDataGenerator called train_datagen \n",
        "    # And a train_generator by calling train_datagen.flow_from_directory\n",
        "\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "    train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "    # Please use a target_size of 150 X 150.\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        \"/tmp/h-or-s\",  \n",
        "        target_size=(150, 150), \n",
        "        batch_size=10,\n",
        "        class_mode='binary')\n",
        "    # Expected output: 'Found 80 images belonging to 2 classes'\n",
        "\n",
        "    history = model.fit_generator(\n",
        "        train_generator,\n",
        "      steps_per_epoch=2,  \n",
        "      epochs=15,\n",
        "      verbose=1,\n",
        "      callbacks=[callbacks])\n",
        "\n",
        "    return history.history['acc'][-1]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9xVDpveFIco",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "308c48a0-a392-400b-a309-cb31fe409cb2"
      },
      "source": [
        "train_happy_sad_model()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 80 images belonging to 2 classes.\n",
            "Epoch 1/15\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 5.6042 - acc: 0.4000\n",
            "Epoch 2/15\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 0.9784 - acc: 0.6500\n",
            "Epoch 3/15\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 0.6986 - acc: 0.4000\n",
            "Epoch 4/15\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 0.7833 - acc: 0.5000\n",
            "Epoch 5/15\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 0.6007 - acc: 0.7500\n",
            "Epoch 6/15\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 0.6048 - acc: 0.6000\n",
            "Epoch 7/15\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 0.3742 - acc: 0.9500\n",
            "Epoch 8/15\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.1724 - acc: 1.0000\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 0.1724 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}